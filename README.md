Information Retrieval Mini Search Engine
Developed by Riddhi Das (Student ID: 20582829)
Course: CS-429 Information Retrieval â€” Fall 2025
ğŸ“Œ Project Overview

This project implements a miniature search engine pipeline consisting of:

A Scrapy-based Web Crawler

Crawls Wikipedia pages starting from a seed URL.

HTML pages are saved locally for indexing.

A Scikit-Learn TF-IDF Indexer

Reads all crawled HTML files.

Extracts text, computes TF-IDF weights, and produces an inverted index (JSON).

A Query Processor & Ranker

Loads the index.

Applies cosine similarity to return Top-K ranked documents.

Outputs results as a CSV.

A Jupyter Notebook Report

Demonstrates code execution, outputs, analysis, and system explanation.

Includes test cases and commentary for each module.

ğŸ“‚ Repository Structure
IR_Project/
â”‚
â”œâ”€â”€ crawler/
â”‚   â”œâ”€â”€ ircrawler/
â”‚   â”‚   â””â”€â”€ spiders/wiki_spider.py     â† Scrapy crawler
â”‚   â””â”€â”€ scrapy.cfg
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ crawl_html/                    â† Crawled Wikipedia HTML files
â”‚   â”œâ”€â”€ queries.csv
â”‚   â”œâ”€â”€ results.csv
â”‚   â””â”€â”€ index.json                     â† Generated inverted index
â”‚
â”œâ”€â”€ indexer/
â”‚   â””â”€â”€ build_index.py                 â† TF-IDF index builder
â”‚
â”œâ”€â”€ processor/
â”‚   â””â”€â”€ rank_queries.py                â† Query ranking script
â”‚
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ project.ipynb                  â† End-to-end analysis + outputs
â”‚
â”œâ”€â”€ crawler_samples/                   â† 2â€“3 sample HTML files for report
â”‚
â””â”€â”€ README.md

ğŸš€ How to Run the Project
1. Run the Scrapy Crawler

From the project root:

cd crawler
scrapy crawl wiki_spider


The HTML files will be saved to:

data/crawl_html/

2. Build the TF-IDF Index

From project root:

python indexer/build_index.py


Creates:

data/index.json

3. Run the Query Ranker
python processor/rank_queries.py


Produces:

data/results.csv

ğŸ§ª Test Cases

The system was tested using:

Valid queries

Highly specific queries

Out-of-vocabulary (garbage) queries

Short single-word queries

All tests ran successfully with correct TF-IDF cosine ranking behavior.

ğŸ“˜ Jupyter Notebook

The notebook includes:

System explanation

Code for crawling, indexing, and ranking

Outputs from each module

Test case results

Final CSV preview

Commentary before every step

This satisfies the course requirement of having write-up + code + outputs in one place.

ğŸ› ï¸ Dependencies

Python 3.12+

Scrapy 2.13+

scikit-learn 1.6+

BeautifulSoup4

Flask (optional, not used in minimal config)

Install via:

pip install -r requirements.txt


(If you want, I can create the requirements.txt file too.)

ğŸ”— Source Code Access

All source code for the crawler, indexer, and ranking system is contained in this repository.
This repository link is included in the project report for verification.

âœï¸ Authorship Statement

This project was developed by Riddhi Das, with logical guidance from ChatGPT.
No external repositories or pre-built IR systems were used.
All code in this repository was written specifically for this assignment.

ğŸ“„ License

This project is for academic use in CS-429 Information Retrieval and is not licensed for redistribution.
